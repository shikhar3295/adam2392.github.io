<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Adam Li - Academic</title><link href="/" rel="alternate"></link><link href="/feeds/academic.atom.xml" rel="self"></link><id>/</id><updated>2017-09-25T00:00:00-04:00</updated><entry><title>Important Papers for Fundamentals in Computational Neuroscience / Data Science</title><link href="/blog/2017/09/fundamental-papers/" rel="alternate"></link><published>2017-09-25T00:00:00-04:00</published><updated>2017-09-25T00:00:00-04:00</updated><author><name>Adam Li</name></author><id>tag:None,2017-09-25:/blog/2017/09/fundamental-papers/</id><summary type="html">&lt;p&gt;To keep a log of important papers I read about and how they are relevant.&lt;/p&gt;</summary><content type="html">&lt;!-- MarkdownTOC --&gt;

&lt;ul&gt;
&lt;li&gt;Papers&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Wilson-Cowan Neural Mass Model&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Kalman Filter Model&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Expectation Maximization&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Information Bottleneck Method&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Opening the Black Box of Deep Neural Networks Via Information&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Reinforcement Learning: An Overview&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Deep Reinforcement Learning: An Overview&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;h1&gt;Papers&lt;/h1&gt;
&lt;h2&gt;1. Wilson-Cowan Neural Mass Model&lt;/h2&gt;
&lt;h3&gt;Summary / Conclusions:&lt;/h3&gt;
&lt;h3&gt;Important Notes:&lt;/h3&gt;
&lt;h2&gt;2. Kalman Filter Model&lt;/h2&gt;
&lt;h3&gt;Summary / Conclusions:&lt;/h3&gt;
&lt;h3&gt;Important Notes:&lt;/h3&gt;
&lt;h2&gt;3. Expectation Maximization&lt;/h2&gt;
&lt;h3&gt;Summary / Conclusions:&lt;/h3&gt;
&lt;h3&gt;Important Notes:&lt;/h3&gt;
&lt;h2&gt;4. Information Bottleneck Method&lt;/h2&gt;
&lt;p&gt;http://www.cs.huji.ac.il/labs/learning/Papers/allerton.pdf&lt;/p&gt;
&lt;h3&gt;Summary / Conclusions:&lt;/h3&gt;
&lt;p&gt;Let us define X as input signal, and Y as desired output.&lt;/p&gt;
&lt;p&gt;Here, they were interested in deriving a quantitative method for optimizing 1) compression rate of a signal and 2) the choice of representation of the original signal.&lt;/p&gt;
&lt;p&gt;Previous theory looked at minimizing the rate of compression given a constraint on expected distortion of the original signal (with new compression). This was solved via iterative algorithm (similar to EM), but lacked generality to find optimal representatives, which minimize the expected distortion (not just compression) of the signal. &lt;/p&gt;
&lt;p&gt;The new theory looks at minimizing the rate of compression given a constraint on the amount of information we can keep about Y using X. This produces an iterative algorithm that also can be solved iteratively. It also shows that 1) the Kullback-Leibler divergence is the relevant distortion measure for the information bottleneck setting, and 2) optimization of representation of signal and the signal compression can be done together.&lt;/p&gt;
&lt;p&gt;This work can be used in applications to information processing problems (e.g. deep learning).&lt;/p&gt;
&lt;h3&gt;Important Notes:&lt;/h3&gt;
&lt;p&gt;Mutual information is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(I(X;Y) = D_{KL}[P(x,y)||P(x)P(y)] = \sum_{x\in X, y\in Y} P(x,y) log(\frac_{P(x,y)}_{P(x)P(y)})\)&lt;/span&gt;
&lt;span class="math"&gt;\(= \sum_{x\in X, y\in Y}P(x,y) log(\frac_{P(x|y)}_{P(x)}) = H(X) - H(X|Y)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;, where &lt;span class="math"&gt;\(D_{KL}(p||q)\)&lt;/span&gt; is the Kullback-Liebler divergence of distributions p and q, and &lt;span class="math"&gt;\(H(X)\)&lt;/span&gt; and &lt;span class="math"&gt;\(H(X|Y)\)&lt;/span&gt; are entropy and conditional entropies, respectively.&lt;/p&gt;
&lt;p&gt;We want the optimal representations of signal X with respect to output label Y. Sufficient statistics are maps/partitions of X, S(X) that captures all the information X has about Y. The mutual information given Y is equal. &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(I(S(X); Y) = I(X; Y)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can allow the map to be stochastic, with encoder P(T|X) and allow map to capture as much as possible of I(X;Y), not necessarily all of it &lt;span class="math"&gt;\(I(S(X); Y) \leq I(X; Y)\)&lt;/span&gt;. Define &lt;span class="math"&gt;\(t \in T\)&lt;/span&gt; as compressed representations of &lt;span class="math"&gt;\(x \in X\)&lt;/span&gt;, stochastically, &lt;span class="math"&gt;\(p(t|x)\)&lt;/span&gt;. The following optimization problem finds a balance between compression of X and prediction of Y.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(min_{p(t|x),p(y|t),p(t)}\ {I(X;T) - \beta I(T;Y)}\)&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;5. Opening the Black Box of Deep Neural Networks Via Information&lt;/h2&gt;
&lt;p&gt;Reference: https://arxiv.org/pdf/1703.00810.pdf&lt;/p&gt;
&lt;h3&gt;Summary / Conclusions:&lt;/h3&gt;
&lt;p&gt;In this paper, the authors extend their analysis of DNN using information theory. They answered the following questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The SGD layer dynamics in the Information plane.
First the layers increase &lt;span class="math"&gt;\(I(T_i;Y)\)&lt;/span&gt;, and then later decrease &lt;span class="math"&gt;\(I(X; T_i)\)&lt;/span&gt;, which corresponds to increasing the information about Y and then later compressing the representation (empirical error minimization &amp;amp; representation compression phase).&lt;/li&gt;
&lt;li&gt;The effect of the training sample size on the layers.
It seems that sample size does not have an effect on empirical error minimization, but does have an effect on the representation compression. Smaller sample sizes has overfitting, which has been seen as overfitting the sample noise. &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What is the benefit of the hidden layers?
Adding hidden layers reduces the number of training epochs. It also seems to accelerate compression, but adding extra width does not seem to help. With layered diffusion of the SGD optimization (backpropagation), it seems that there is an exponential decrease in epochs with K hidden layers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What is the final location of the hidden layers?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do the hidden layers form optimal IB representations?
It seems that the hidden layers converge to the optiaml IB representations. However, we can see that there can be clearly many different layers that correspond to the same IB representation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another important hypothesis/conjecture they make is that: attempts to interpret single weights, or even single neurons in such networks can be meaningless because there is a large number of different networks that can achieve optimal performance. This makes sense in terms of how the brain is structured; the brain does not form the same pathway for learning something new between different people, but form a unique network for optimal performance. &lt;/p&gt;
&lt;h3&gt;Important Notes:&lt;/h3&gt;
&lt;p&gt;First, they estimated the mutual information of the layers with the input and with the labels &lt;span class="math"&gt;\(I(X;T_i)\)&lt;/span&gt; and &lt;span class="math"&gt;\(I(T_i;Y)\)&lt;/span&gt;. &lt;/p&gt;
&lt;h2&gt;6. Reinforcement Learning: An Overview&lt;/h2&gt;
&lt;p&gt;Reference: https://pdfs.semanticscholar.org/b373/b0c6e3b4fef4ac0534965708fc382343f8dc.pdf&lt;/p&gt;
&lt;h3&gt;Summary / Conclusions:&lt;/h3&gt;
&lt;h3&gt;Important Notes:&lt;/h3&gt;
&lt;h2&gt;7. Deep Reinforcement Learning: An Overview&lt;/h2&gt;
&lt;p&gt;Reference: &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="phd"></category><category term="journals"></category><category term="reviews"></category></entry><entry><title>Introduction to EEG Data Analysis</title><link href="/blog/2017/09/primer-eeg-analysis/" rel="alternate"></link><published>2017-09-18T00:00:00-04:00</published><updated>2017-09-18T00:00:00-04:00</updated><author><name>Adam Li</name></author><id>tag:None,2017-09-18:/blog/2017/09/primer-eeg-analysis/</id><summary type="html">&lt;p&gt;To guide the introduction of EEG analysis.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Background&lt;/h1&gt;
&lt;h1&gt;Data &amp;amp; Metadata&lt;/h1&gt;
&lt;h1&gt;Implementation&lt;/h1&gt;</content><category term="data analysis"></category><category term="eeg"></category><category term="phd"></category></entry><entry><title>Doctoral Board Oral Exam (PhD)</title><link href="/blog/2017/08/doctoral-board-oral/" rel="alternate"></link><published>2017-08-05T00:00:00-04:00</published><updated>2017-08-05T00:00:00-04:00</updated><author><name>Adam Li</name></author><id>tag:None,2017-08-05:/blog/2017/08/doctoral-board-oral/</id><summary type="html">&lt;p&gt;A short walkthrough of my experience with the DBO exam at Johns Hopkins University&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Doctoral Board Oral Exam&lt;/h1&gt;
&lt;!-- MarkdownTOC --&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Cable Theory and Compartmental Modeling&lt;/li&gt;
&lt;li&gt;Examples of different types of neurons&lt;/li&gt;
&lt;li&gt;Approach&lt;/li&gt;
&lt;li&gt;Important Equations&lt;/li&gt;
&lt;li&gt;Study&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Generalized Linear Models:&lt;/li&gt;
&lt;li&gt;General Form of Exponential Family Distribution&lt;/li&gt;
&lt;li&gt;Normal Linear Regression&lt;/li&gt;
&lt;li&gt;Logistic Regression&lt;/li&gt;
&lt;li&gt;Poisson Regression&lt;/li&gt;
&lt;li&gt;Solving GLM Methods:&lt;/li&gt;
&lt;li&gt;Goodness of Fit&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Kalman Filter&lt;/li&gt;
&lt;li&gt;Stochastic State-Space Model&lt;/li&gt;
&lt;li&gt;Assumptions&lt;/li&gt;
&lt;li&gt;Derivation&lt;/li&gt;
&lt;li&gt;Relation to a Least-Squares Problem&lt;/li&gt;
&lt;li&gt;Relation to a Bayesian Maximum Aposteri Estimation&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Expectation Maximization&lt;/li&gt;
&lt;li&gt;Basic Idea&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;K-Means Algorithm&lt;/li&gt;
&lt;li&gt;Cost Function&lt;/li&gt;
&lt;li&gt;The Algorithm&lt;/li&gt;
&lt;li&gt;Initialization&lt;/li&gt;
&lt;li&gt;Convergence&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Sensory Pathways and Systems in Neuroscience&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Motor Pathways and Systems in Neuroscience&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;General Systems in Neuroscience&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Gaussian Mixture Models&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;FAQ&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;h1&gt;1. Cable Theory and Compartmental Modeling&lt;/h1&gt;
&lt;h2&gt;Examples of different types of neurons&lt;/h2&gt;
&lt;p&gt;There are thalamic cells, pyramidal cells, double pyramidal cells, granule cells, purkinje cells. These all have different morphologies and perform different computations.&lt;/p&gt;
&lt;h2&gt;Approach&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Approximate dendrites as uniform membrane cylandiers&lt;/li&gt;
&lt;li&gt;Synaptic inputs are approximated as 'injected currents'&lt;/li&gt;
&lt;li&gt;Use the cable equation to create a system of differential equations for each cylinder.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Important Equations&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;input conductance of semi-infinite cable&lt;/li&gt;
&lt;li&gt;input conductance of infinite cable&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Unsealed end:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;cable equation&lt;/li&gt;
&lt;li&gt;input conductance of finite cable&lt;/li&gt;
&lt;li&gt;s.s. voltage along cable&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Sealed end:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;input conductance of the finite cable&lt;/li&gt;
&lt;li&gt;s.s. voltage along cable&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Concatenated Cables:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Compute V(X) along branches, by determining &lt;span class="math"&gt;\(G_{out}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Definitions:&lt;/h3&gt;
&lt;p&gt;Know definitions and related biology of:
- axial resistance, the resistance to current flow along the uniform cable (along the dendrite)
- membrane resistance, the resistance of current flow out of the dendrite
- membrance capacitance, the capacitance of a patch of membrane surface area
- derive cable equation as a model of concatenated RC circuits&lt;/p&gt;
&lt;h3&gt;Compartmental Models:&lt;/h3&gt;
&lt;p&gt;Be able to derive system of equations into a matrix form for a linear time-invariant system &lt;/p&gt;
&lt;p&gt;Understand how transfer resistances work. Understand how distributing synaptic inputs works. &lt;/p&gt;
&lt;p&gt;Understand how coincidence detection (AND operator), shunting inhibition (AND-NOT operator).&lt;/p&gt;
&lt;h2&gt;Study&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Definitions of cable theory and biological relations&lt;/li&gt;
&lt;li&gt;Solving single cable equation and different boundary conditions&lt;/li&gt;
&lt;li&gt;Derivation of cable equation under different boundary conditions&lt;/li&gt;
&lt;li&gt;Deriving LTI system from compartmental models of cables&lt;/li&gt;
&lt;li&gt;Derive transfer resistances&lt;/li&gt;
&lt;li&gt;Derive AND operator (coincidence detection)&lt;/li&gt;
&lt;li&gt;Derive AND-NOT operator (shunting inhibition)&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;2. Generalized Linear Models:&lt;/h1&gt;
&lt;h2&gt;General Form of Exponential Family Distribution&lt;/h2&gt;
&lt;p&gt;Be able to define all the terms, such as: natural paramters, sufficient statistic, natural link function, dispersion parameter&lt;/p&gt;
&lt;h2&gt;Normal Linear Regression&lt;/h2&gt;
&lt;h2&gt;Logistic Regression&lt;/h2&gt;
&lt;h2&gt;Poisson Regression&lt;/h2&gt;
&lt;h2&gt;Solving GLM Methods:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Penalized Quasi-likelihood&lt;/li&gt;
&lt;li&gt;Laplace's Method&lt;/li&gt;
&lt;li&gt;Adaptive Gaussian Quadrature&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Goodness of Fit&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Chi-square test&lt;/li&gt;
&lt;li&gt;Kolmogorov Statistic&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;3. Kalman Filter&lt;/h1&gt;
&lt;h2&gt;Stochastic State-Space Model&lt;/h2&gt;
&lt;p&gt;Here, list the linear, time-invariant system with a state evolution equation and measurement/observation equation.&lt;/p&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;state and observation noises are independent, zero-mean Gaussian white processes with some defined covariances&lt;/li&gt;
&lt;li&gt;initial state x_0 is a Gaussian R.V. independent of the state/observation noises&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Derivation&lt;/h2&gt;
&lt;p&gt;Derive the Kalman filter equations for the state update, covarariance estimates&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Measurement update&lt;/li&gt;
&lt;li&gt;Time update&lt;/li&gt;
&lt;li&gt;Combined Update&lt;/li&gt;
&lt;li&gt;Covariance Update&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Relation to a Least-Squares Problem&lt;/h2&gt;
&lt;h2&gt;Relation to a Bayesian Maximum Aposteri Estimation&lt;/h2&gt;
&lt;h1&gt;4. Expectation Maximization&lt;/h1&gt;
&lt;h2&gt;Basic Idea&lt;/h2&gt;
&lt;p&gt;By computing the likelihood of your unknown parameters, based on known outcomes. You can perform maximum likelihood estimation to get the best estimate of the unknown parameters&lt;/p&gt;
&lt;h1&gt;5. K-Means Algorithm&lt;/h1&gt;
&lt;h2&gt;Cost Function&lt;/h2&gt;
&lt;p&gt;The cost function is attempting to minimize the distortion (distance to centers) for every point in the set of data points, S.&lt;/p&gt;
&lt;h2&gt;The Algorithm&lt;/h2&gt;
&lt;p&gt;'''
Input: k clusters
initialize centers: z_1, ..., z_k \in \real^d and clusters C_1, ..., C_k
repeat until there is no further change in L(z, C):
    for each j (data point): C_j &amp;lt;- {x \in S whose closest center is z_j}
    for each j (data point): z_j &amp;lt;- mean(C_j) 
'''&lt;/p&gt;
&lt;p&gt;Walk through for a small example to see how the algorithm works:
(0, 0, 0)
(0, 0.5, 1)
(1, 3, 2)
(4, 5, 6)
(2, 3, 1)
(5, 2, 0)
(0, 1, 0)
(1, 1, 0)
(2, 1, 0)&lt;/p&gt;
&lt;h2&gt;Initialization&lt;/h2&gt;
&lt;h2&gt;Convergence&lt;/h2&gt;
&lt;p&gt;Show that the cost monotonically decreases, so the algorithm will converge at least in the sense of cost decreasing to a non-changing amount.&lt;/p&gt;
&lt;h1&gt;6. Sensory Pathways and Systems in Neuroscience&lt;/h1&gt;
&lt;h1&gt;7. Motor Pathways and Systems in Neuroscience&lt;/h1&gt;
&lt;h1&gt;8. General Systems in Neuroscience&lt;/h1&gt;
&lt;h1&gt;9. Gaussian Mixture Models&lt;/h1&gt;
&lt;h1&gt;FAQ&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Q: Where should I stay? 
A: Generally, I'm an advocate of staying downtown because then everything is walking distance. If not, I would try to stay within walking distance to a subway station. Stay away from South Chicago because that is a very crime-ridden area.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q: I only have a day in Seoul, where should I go?
A: Purple pig, Girl on the goat, Lou Malnati's to eat. Cloud Gate / Millenium Park and the River Walk to see. Signature Room for a night time drink if you have the time.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="doctoral board oral"></category><category term="phd"></category><category term="johns hopkins"></category></entry></feed>