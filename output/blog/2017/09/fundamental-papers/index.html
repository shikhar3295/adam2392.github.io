<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>Important Papers for Fundamentals in Computational Neuroscience / Data Science - Adam Li</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="/blog/2017/09/fundamental-papers/">

        <meta name="author" content="Adam Li" />
        <meta name="keywords" content="phd,journals,reviews" />
        <meta name="description" content="To keep a log of important papers I read about and how they are relevant." />

        <meta property="og:site_name" content="Adam Li" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="Important Papers for Fundamentals in Computational Neuroscience / Data Science"/>
        <meta property="og:url" content="/blog/2017/09/fundamental-papers/"/>
        <meta property="og:description" content="To keep a log of important papers I read about and how they are relevant."/>
        <meta property="article:published_time" content="2017-09-25" />
            <meta property="article:section" content="Academic" />
            <meta property="article:tag" content="phd" />
            <meta property="article:tag" content="journals" />
            <meta property="article:tag" content="reviews" />
            <meta property="article:author" content="Adam Li" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>

        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Adam Li ATOM Feed"/>



        <link href="/feeds/academic.atom.xml" type="application/atom+xml" rel="alternate"
              title="Adam Li Academic ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">
Adam Li            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                    <li><a href="/categories.html">Blog</a></li>
                    <li><a href="/archives.html">Timeline</a></li>
                    <li><a href="/tags.html">Tags</a></li>
                    <li><a href="/pdfs/AdamLi_CV.pdf">Curriculum Vitae</a></li>
                         <li><a href="/contact/">
                             Contact
                          </a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="/blog/2017/09/fundamental-papers/"
                       rel="bookmark"
                       title="Permalink to Important Papers for Fundamentals in Computational Neuroscience / Data Science">
                        Important Papers for Fundamentals in Computational Neuroscience / Data Science
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2017-09-25T00:00:00-04:00"> Mon 25 September 2017</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="/tag/phd.html">phd</a>
        /
	<a href="/tag/journals.html">journals</a>
        /
	<a href="/tag/reviews.html">reviews</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <!-- MarkdownTOC -->

<ul>
<li>Papers<ul>
<li>
<ol>
<li>Wilson-Cowan Neural Mass Model</li>
<li>Summary / Conclusions:</li>
<li>Important Notes:</li>
</ol>
</li>
<li>
<ol>
<li>Kalman Filter Model</li>
<li>Summary / Conclusions:</li>
<li>Important Notes:</li>
</ol>
</li>
<li>
<ol>
<li>Expectation Maximization</li>
<li>Summary / Conclusions:</li>
<li>Important Notes:</li>
</ol>
</li>
<li>
<ol>
<li>Information Bottleneck Method</li>
<li>Summary / Conclusions:</li>
<li>Important Notes:</li>
</ol>
</li>
<li>
<ol>
<li>Opening the Black Box of Deep Neural Networks Via Information</li>
<li>Summary / Conclusions:</li>
<li>Important Notes:</li>
</ol>
</li>
<li>
<ol>
<li>Reinforcement Learning: An Overview</li>
<li>Summary / Conclusions:</li>
<li>Important Notes:</li>
</ol>
</li>
<li>
<ol>
<li>Deep Reinforcement Learning: An Overview</li>
</ol>
</li>
<li>
<ol>
<li>Variational Inference:</li>
<li>Summary / Conclusions</li>
<li>Important Notes</li>
</ol>
</li>
</ul>
</li>
</ul>
<!-- /MarkdownTOC -->

<h1>Papers</h1>
<h2>1. Wilson-Cowan Neural Mass Model</h2>
<h3>Summary / Conclusions:</h3>
<h3>Important Notes:</h3>
<h2>2. Kalman Filter Model</h2>
<h3>Summary / Conclusions:</h3>
<h3>Important Notes:</h3>
<h2>3. Expectation Maximization</h2>
<h3>Summary / Conclusions:</h3>
<h3>Important Notes:</h3>
<h2>4. Information Bottleneck Method</h2>
<p>http://www.cs.huji.ac.il/labs/learning/Papers/allerton.pdf</p>
<h3>Summary / Conclusions:</h3>
<p>Let us define X as input signal, and Y as desired output.</p>
<p>Here, they were interested in deriving a quantitative method for optimizing 1) compression rate of a signal and 2) the choice of representation of the original signal.</p>
<p>Previous theory looked at minimizing the rate of compression given a constraint on expected distortion of the original signal (with new compression). This was solved via iterative algorithm (similar to EM), but lacked generality to find optimal representatives, which minimize the expected distortion (not just compression) of the signal. </p>
<p>The new theory looks at minimizing the rate of compression given a constraint on the amount of information we can keep about Y using X. This produces an iterative algorithm that also can be solved iteratively. It also shows that 1) the Kullback-Leibler divergence is the relevant distortion measure for the information bottleneck setting, and 2) optimization of representation of signal and the signal compression can be done together.</p>
<p>This work can be used in applications to information processing problems (e.g. deep learning).</p>
<h3>Important Notes:</h3>
<p>Mutual information is defined as:</p>
<p><span class="math">\(I(X;Y) = D_{KL}[P(x,y)||P(x)P(y)] = \sum_{x\in X, y\in Y} P(x,y) log(\frac_{P(x,y)}_{P(x)P(y)})\)</span>
<span class="math">\(= \sum_{x\in X, y\in Y}P(x,y) log(\frac_{P(x|y)}_{P(x)}) = H(X) - H(X|Y)\)</span></p>
<p>, where <span class="math">\(D_{KL}(p||q)\)</span> is the Kullback-Liebler divergence of distributions p and q, and <span class="math">\(H(X)\)</span> and <span class="math">\(H(X|Y)\)</span> are entropy and conditional entropies, respectively.</p>
<p>We want the optimal representations of signal X with respect to output label Y. Sufficient statistics are maps/partitions of X, S(X) that captures all the information X has about Y. The mutual information given Y is equal. </p>
<p><span class="math">\(I(S(X); Y) = I(X; Y)\)</span></p>
<p>We can allow the map to be stochastic, with encoder P(T|X) and allow map to capture as much as possible of I(X;Y), not necessarily all of it <span class="math">\(I(S(X); Y) \leq I(X; Y)\)</span>. Define <span class="math">\(t \in T\)</span> as compressed representations of <span class="math">\(x \in X\)</span>, stochastically, <span class="math">\(p(t|x)\)</span>. The following optimization problem finds a balance between compression of X and prediction of Y.</p>
<p><span class="math">\(min_{p(t|x),p(y|t),p(t)}\ {I(X;T) - \beta I(T;Y)}\)</span></p>
<h2>5. Opening the Black Box of Deep Neural Networks Via Information</h2>
<p>Reference: https://arxiv.org/pdf/1703.00810.pdf</p>
<h3>Summary / Conclusions:</h3>
<p>In this paper, the authors extend their analysis of DNN using information theory. They answered the following questions:</p>
<ol>
<li>The SGD layer dynamics in the Information plane.
First the layers increase <span class="math">\(I(T_i;Y)\)</span>, and then later decrease <span class="math">\(I(X; T_i)\)</span>, which corresponds to increasing the information about Y and then later compressing the representation (empirical error minimization &amp; representation compression phase).</li>
<li>The effect of the training sample size on the layers.
It seems that sample size does not have an effect on empirical error minimization, but does have an effect on the representation compression. Smaller sample sizes has overfitting, which has been seen as overfitting the sample noise. </li>
<li>
<p>What is the benefit of the hidden layers?
Adding hidden layers reduces the number of training epochs. It also seems to accelerate compression, but adding extra width does not seem to help. With layered diffusion of the SGD optimization (backpropagation), it seems that there is an exponential decrease in epochs with K hidden layers.</p>
</li>
<li>
<p>What is the final location of the hidden layers?</p>
</li>
<li>
<p>Do the hidden layers form optimal IB representations?
It seems that the hidden layers converge to the optiaml IB representations. However, we can see that there can be clearly many different layers that correspond to the same IB representation.</p>
</li>
</ol>
<p>Another important hypothesis/conjecture they make is that: attempts to interpret single weights, or even single neurons in such networks can be meaningless because there is a large number of different networks that can achieve optimal performance. This makes sense in terms of how the brain is structured; the brain does not form the same pathway for learning something new between different people, but form a unique network for optimal performance. </p>
<h3>Important Notes:</h3>
<p>First, they estimated the mutual information of the layers with the input and with the labels <span class="math">\(I(X;T_i)\)</span> and <span class="math">\(I(T_i;Y)\)</span>. </p>
<h2>6. Reinforcement Learning: An Overview</h2>
<p>Reference: https://pdfs.semanticscholar.org/b373/b0c6e3b4fef4ac0534965708fc382343f8dc.pdf</p>
<h3>Summary / Conclusions:</h3>
<h3>Important Notes:</h3>
<h2>7. Deep Reinforcement Learning: An Overview</h2>
<p>Reference:</p>
<h2>8. Variational Inference:</h2>
<h3>Summary / Conclusions</h3>
<p>Variational inference</p>
<h3>Important Notes</h3>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </div>
            <!-- /.entry-content -->
<section class="well" id="related-posts">
    <h4>Related Posts:</h4>
    <ul>
        <li><a href="/blog/2017/09/fundamental-computational-modeling/">Important Concepts for Computational Modeling</a></li>
        <li><a href="/blog/2018/06/whitaker-summary-experience/">Using The Virtual Brain to Understand Algorithms</a></li>
        <li><a href="/blog/2017/08/doctoral-board-oral/">Doctoral Board Oral Exam (PhD)</a></li>
        <li><a href="/blog/2017/12/using-freesurfer/">Using FreeSurfer</a></li>
        <li><a href="/blog/2017/09/simulating-tvb/">Simulating Epileptic iEEG Activity Using The Virtual Brain</a></li>
    </ul>
</section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://twitter.com/adam2392"><i class="fa fa-twitter-square fa-lg"></i> twitter</a></li>
    <li class="list-group-item"><a href="https://stackexchange.com/users/4494355/ajl123"><i class="fa fa-stack-overflow fa-lg"></i> stack-overflow</a></li>
    <li class="list-group-item"><a href="https://github.com/adam2392"><i class="fa fa-github-square fa-lg"></i> github</a></li>
    <li class="list-group-item"><a href="https://www.linkedin.com/in/adam2392"><i class="fa fa-linkedin-square fa-lg"></i> linkedin</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Github -->
<li class="list-group-item">
  <h4><i class="fa fa-github fa-lg"></i><span class="icon-label">GitHub Repos</span></h4>
  <div id="gh_repos">
    <p class="list-group-item">Status updating...</p>
  </div>
</li>
<!-- End Sidebar/Github -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2018 Adam Li
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>


<!-- GitHub JS Code -->
<script type="text/javascript">
$(document).ready(function () {
  if (!window.jXHR) {
    var jxhr = document.createElement('script');
    jxhr.type = 'text/javascript';
    jxhr.src = '/theme/js/jXHR.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(jxhr, s);
  }

  github.showRepos({
    user: 'adam2392',
    count: 5,
    skip_forks: false,
    target: '#gh_repos'
  });
});
</script>
<script src="/theme/js/github.js" type="text/javascript"></script>
<!-- End GitHub JS Code -->
    <!-- Google Analytics -->
    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-106551801-1']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <!-- End Google Analytics Code -->


</body>
</html>